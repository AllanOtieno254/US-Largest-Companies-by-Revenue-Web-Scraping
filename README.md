# ğŸ¢ US Largest Companies Web Scraping Project

Welcome to the **US Largest Companies Web Scraping Project** repository! This project focuses on extracting, analyzing, and visualizing data from the Wikipedia page listing the largest companies in the United States by revenue.

![Companies](https://upload.wikimedia.org/wikipedia/commons/8/89/NYC_Times_Square_wide_angle.jpg)

## ğŸ“‘ Project Overview

In this project, we have developed a Python-based web scraper that extracts the list of the largest companies in the United States by revenue from [Wikipedia](https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue). The data is then cleaned, analyzed, and saved in a CSV format for further use.

### Features:
- Automated data extraction from Wikipedia.
- Data cleaning and preprocessing.
- Saving the cleaned data in CSV format.
- Basic data analysis and visualization.
- User-friendly and easy to understand.

## ğŸ“Š Data Description

The data scraped includes the following information:
- **Rank**: The rank of the company based on revenue.
- **Company Name**: The name of the company.
- **Industry**: The industry to which the company belongs.
- **Revenue**: Total revenue generated by the company (in billions of USD).
- **Headquarters**: The location of the company's headquarters.
- **Employees**: Number of employees in the company.

## ğŸ›  Technologies Used

- **Python**: The primary programming language used for scraping and data analysis.
- **BeautifulSoup4**: For parsing HTML and XML documents.
- **Pandas**: For data manipulation and analysis.
- **Requests**: For making HTTP requests to retrieve web pages.
- **Jupyter Notebook**: For data analysis and visualization.

## ğŸ”§ Installation and Setup

1. **Clone the repository**:
   ```bash
   git clone https://github.com/YourUsername/US-Largest-Companies-Web-Scraping.git
   cd US-Largest-Companies-Web-Scraping
